---
title: Notes for live stream
draft: true
---

# Notes for pitch


Hi all,

What a week it has been! Probably you felt as exhausted as me. A first course week can be challenging. Some of you even had just started their education at Tilburg University!

In any case, the snow this weekend helped me relax a little bit, and I hope you could do the same.

You're now starting with your second course week in Data Preparation and Workflow Management.

Let's briefly recap: last week, you have followed your first tutorial on using R. In the lab, we've met to work through the tutorial with another data set - by InsideAirbnb. If you haven't had the chance to take a look at it, check out the recording, which is available in YouTube.

This week is all about versioning and collaboration. Versioning means working on code, and being able to roll back to any previous version of a file. Think of it like an unlimited Dropbox. And collaborating, well, that's something we all need when we work on empirical research projects. For example, you may want to show code to colleagues and ask them for feedback. Of course, they not only need to be able to look at the code, but also be able to run it.

While these skills - versioning and collaboration - may seem far-fetched at this moment, students last year actually found these concepts so enriching that we decided to show them to you very early on in this class.

So this week, you get acquinted with GitHub - the tool used across many industries to manage code and collaborate on large-scale software projects.

At this stage, don't feel afraid: like last week, I have worked on a gentle introduction to using GitHub. Rather than writing actual software code, you'll be working on very simple markdown code to format text written on the course website, or on Tilburg Science Hub.

Next to the tutorial, you'll learn about important concepts on how to collaborate in a team project. And if your'e curious on the underpinnings of all this, I have referenced two optional readings on the site.

As for the team project, it's also time to find class mates to join your group. In this week's live stream, you can obtain feedback on your Research Motivation & Repository structure. Wonder how to prepare for our session on Thursday? Well - set up your repository and add a readme to it! We'll use it in class to discuss your work.

Does team work come to you as a surprise? Head over to the course's project section, and view the workplan which has all the deadlines and details to get started!

So, now it's really time for you to get started! Be in touch on WhatsApp to obtain support! I look forward seeing you in the livestream this week. Check your schedule, as the timing is a little different than in other weeks.

See you soon! Cheers!



<!--s
 got introduced in working with R. You followed a tutorial and familiarized yourself


discovered R as a tool to explore datasets you've never seen before. You learned how to read those datasets into your computer's memory and then started to summarize the data in RMarkdowns. I really like RMarkdowns, as they look and feel nice but still allow you to work with code so you can always reproduce your results later.

The focus of this second course week is to build your data preparation skills. You may rightly wonder: wait - didn't I do this last week? Well, last week, you've only looked at raw data! This week, you're going to take the raw data and convert it into a dataset that you can actually analyze later.

For example, in my research on Spotify, I obtained data that listed, for every user, the songs they listened to, including the exact time stamps of when that happened. That's the raw data. However, for analysis, I needed to aggregate that data at the weekly level. So instead of seeing user, A listened to song B on the 1st of January at one a clock, I needed to *count all the songs user A has listened* in the first week of January. That difference sounds subtle, but it *is* super important. I typically refer to this data as a "derived" data set, as it is derived from the raw data. Sometimes, I also like to call it "cleaned", or "precleaned" data.

You're going to discover a lot of ways in which to prepare data for analysis. And the tutorial on Data Preparation in R is probably the biggest task for you to work on this week.

On top of it, you're going to study an article on Marketing Analytics for Data-Rich Environments. The article was written by two colleagues who work at the University of Maryland. It introduces you to the world of marketing and how we actually became a data-driven discipline. You'll learn, among others, about the various types of data that are available to us: what really is the difference between structured and unstructured data? What data is needed to conduct marketing-mix modeling? And which data can be used to conduct research on personalization or security and privacy issues?

In starting this week, remember to use the support chat on WhatsApp! I’m open to chat between 9 and 5 every weekday, except Thursdays. You can text me also outside of my working hours. If your question becomes outdated, just delete it from the chat so I don’t have to take a look at it when I return to my desk during regular working hours.

Finally, please keep an eye on the course page and Canvas for updates.


I look forward to seeing you on Friday!
